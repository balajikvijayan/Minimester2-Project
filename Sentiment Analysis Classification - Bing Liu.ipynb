{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import nltk\n",
    "from collections import Counter\n",
    "from nltk.tokenize import wordpunct_tokenize\n",
    "from nltk import bigrams\n",
    "from nltk import trigrams\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer,CountVectorizer\n",
    "from sklearn.decomposition import NMF\n",
    "from sklearn.cross_validation import KFold, train_test_split\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score,\\\n",
    "                    f1_score\n",
    "from sklearn.ensemble import BaggingClassifier, AdaBoostClassifier\n",
    "from pymongo import MongoClient\n",
    "from code.util import Util"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Lists for X and y\n",
    "review_list, opinion_list, sentiword_list, sentiment_list, word_list,\\\n",
    "            pos, neg = [],[],[],[],[],[],[]\n",
    "vocab = {}\n",
    "    \n",
    "#PyMongo variables\n",
    "client = MongoClient()\n",
    "db = client['reviews']\n",
    "collection = db['movies']\n",
    "reviews = collection.find()\n",
    "\n",
    "db1 = client['sentiment']\n",
    "collection1 = db1['bingliu']\n",
    "sentiments = collection1.find()\n",
    "\n",
    "#build review and label lists\n",
    "for review in reviews:\n",
    "    opinion_list.append(review['Opinion'])\n",
    "    review_list.append(review['Review'])\n",
    "\n",
    "#build sentiment word, sentiment polarity, pos word, neg word\n",
    "for sentiment in sentiments:\n",
    "    sentiword_list.append(sentiment['Word'])\n",
    "    sentiment_list.append(sentiment['Sentiment'])\n",
    "    if sentiment['Sentiment'] == 1:\n",
    "        pos.append(sentiment['Word'])\n",
    "    elif sentiment['Sentiment'] == -1:\n",
    "        neg.append(sentiment['Word'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bernoulli NB\n",
      "Train Accuracy : 0.712666666667\n",
      "Test Accuracy : 0.698\n",
      "Logistic Regression\n",
      "Train Accuracy : 0.835333333333\n",
      "Test Accuracy : 0.84\n",
      "SVC\n",
      "Train Accuracy : 0.475333333333\n",
      "Test Accuracy : 0.498\n"
     ]
    }
   ],
   "source": [
    "vectorizer = TfidfVectorizer(decode_error='replace',strip_accents='unicode',\\\n",
    "                            vocabulary = sentiword_list, lowercase=True)\n",
    "review_tf = vectorizer.fit_transform(review_list)\n",
    "review_sf = review_tf.copy()\n",
    "\n",
    "#for every review\n",
    "for i, review_s in enumerate(review_tf):\n",
    "    #for every index (word) in the review\n",
    "    for idx in review_tf[i].indices:\n",
    "        if vectorizer.vocabulary[idx] in neg:\n",
    "            review_sf[i, idx] = review_tf[i, idx]*-1\n",
    "        elif vectorizer.vocabulary[idx] in pos:\n",
    "            review_sf[i, idx] = review_tf[i, idx]\n",
    "\n",
    "X = review_sf.sum(axis=1)\n",
    "\n",
    "feats_train, feats_test, opinions_train, opinions_test = train_test_split(\\\n",
    "                    review_sf, opinion_array)\n",
    "kf = KFold(feats_train.shape[0], n_folds=5)\n",
    "\n",
    "utility = Util()\n",
    "train_accuracy, test_accuracy = utility.CalculateAccuracy(BernoulliNB(),\\\n",
    "            5, feats_train, opinions_train, feats_test, opinions_test)\n",
    "print 'Bernoulli NB'\n",
    "print 'Train Accuracy : {}'.format(train_accuracy)\n",
    "print 'Test Accuracy : {}'.format(test_accuracy)\n",
    "\n",
    "train_accuracy, test_accuracy = utility.CalculateAccuracy(\\\n",
    "    LogisticRegression(),5, feats_train, opinions_train,\\\n",
    "    feats_test, opinions_test)\n",
    "print 'Logistic Regression'\n",
    "print 'Train Accuracy : {}'.format(train_accuracy)\n",
    "print 'Test Accuracy : {}'.format(test_accuracy)\n",
    "\n",
    "train_accuracy, test_accuracy = utility.CalculateAccuracy(\\\n",
    "    SVC(),5, feats_train, opinions_train, feats_test,\\\n",
    "    opinions_test)\n",
    "print 'SVC'\n",
    "print 'Train Accuracy : {}'.format(train_accuracy)\n",
    "print 'Test Accuracy : {}'.format(test_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bernoulli NB\n",
      "Train Accuracy : 0.81\n",
      "Test Accuracy : 0.806\n",
      "Logistic Regression\n",
      "Train Accuracy : 0.828\n",
      "Test Accuracy : 0.8028\n",
      "SVC\n",
      "Train Accuracy : 0.554\n",
      "Test Accuracy : 0.578\n"
     ]
    }
   ],
   "source": [
    "vectorizer = CountVectorizer(decode_error='replace',strip_accents='unicode',\\\n",
    "                            vocabulary = sentiword_list)\n",
    "review_tf = vectorizer.fit_transform(review_list)\n",
    "\n",
    "feats_train, feats_test, opinions_train, opinions_test = train_test_split(\\\n",
    "                    review_tf, opinion_array)\n",
    "kf = KFold(feats_train.shape[0], n_folds=5)\n",
    "\n",
    "utility = Util()\n",
    "train_accuracy, test_accuracy = utility.CalculateAccuracy(BernoulliNB(),\\\n",
    "            5, feats_train, opinions_train, feats_test, opinions_test)\n",
    "print 'Bernoulli NB'\n",
    "print 'Train Accuracy : {}'.format(train_accuracy)\n",
    "print 'Test Accuracy : {}'.format(test_accuracy)\n",
    "\n",
    "train_accuracy, test_accuracy = utility.CalculateAccuracy(\\\n",
    "    LogisticRegression(),5, feats_train, opinions_train,\\\n",
    "    feats_test, opinions_test)\n",
    "print 'Logistic Regression'\n",
    "print 'Train Accuracy : {}'.format(train_accuracy)\n",
    "print 'Test Accuracy : {}'.format(test_accuracy)\n",
    "\n",
    "train_accuracy, test_accuracy = utility.CalculateAccuracy(\\\n",
    "    SVC(),5, feats_train, opinions_train, feats_test,\\\n",
    "    opinions_test)\n",
    "print 'SVC'\n",
    "print 'Train Accuracy : {}'.format(train_accuracy)\n",
    "print 'Test Accuracy : {}'.format(test_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bernoulli NB\n",
      "Train Accuracy : 0.699333333333\n",
      "Test Accuracy : 0.7\n",
      "Logistic Regression\n",
      "Train Accuracy : 0.698666666667\n",
      "Test Accuracy : 0.702\n",
      "SVC\n",
      "Train Accuracy : 0.694666666667\n",
      "Test Accuracy : 0.696\n"
     ]
    }
   ],
   "source": [
    "vectorizer = CountVectorizer(decode_error='replace',strip_accents='unicode',\\\n",
    "                            vocabulary = sentiword_list)\n",
    "review_tf = vectorizer.fit_transform(review_list)\n",
    "\n",
    "# print review_tf[0].indices\n",
    "review_sf = review_tf.copy()\n",
    "\n",
    "#for every review\n",
    "for i, review_s in enumerate(review_tf):\n",
    "    #for every index (word) in the review\n",
    "    for idx in review_tf[i].indices:\n",
    "        if vectorizer.vocabulary[idx] in neg:\n",
    "            review_sf[i, idx] = review_tf[i, idx]*-1\n",
    "        elif vectorizer.vocabulary[idx] in pos:\n",
    "            review_sf[i, idx] = review_tf[i, idx]\n",
    "\n",
    "X = review_sf.sum(axis=1)\n",
    "\n",
    "opinion_array = np.array(opinion_list)\n",
    "\n",
    "feats_train, feats_test, opinions_train, opinions_test = train_test_split(\\\n",
    "                    X, opinion_array)\n",
    "kf = KFold(feats_train.shape[0], n_folds=5)\n",
    "\n",
    "utility = Util()\n",
    "train_accuracy, test_accuracy = utility.CalculateAccuracy(BernoulliNB(),\\\n",
    "            5, feats_train, opinions_train, feats_test, opinions_test)\n",
    "print 'Bernoulli NB'\n",
    "print 'Train Accuracy : {}'.format(train_accuracy)\n",
    "print 'Test Accuracy : {}'.format(test_accuracy)\n",
    "\n",
    "train_accuracy, test_accuracy = utility.CalculateAccuracy(\\\n",
    "    LogisticRegression(),5, feats_train, opinions_train,\\\n",
    "    feats_test, opinions_test)\n",
    "print 'Logistic Regression'\n",
    "print 'Train Accuracy : {}'.format(train_accuracy)\n",
    "print 'Test Accuracy : {}'.format(test_accuracy)\n",
    "\n",
    "train_accuracy, test_accuracy = utility.CalculateAccuracy(\\\n",
    "    SVC(),5, feats_train, opinions_train, feats_test,\\\n",
    "    opinions_test)\n",
    "print 'SVC'\n",
    "print 'Train Accuracy : {}'.format(train_accuracy)\n",
    "print 'Test Accuracy : {}'.format(test_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bagging (Trees)\n",
      "Train Accuracy : 0.693333333333\n",
      "Test Accuracy : 0.7156\n",
      "Bagging (Logit)\n",
      "Train Accuracy : 0.689333333333\n",
      "Test Accuracy : 0.73\n",
      "Bagging (SVC)\n",
      "Train Accuracy : 0.681333333333\n",
      "Test Accuracy : 0.71\n",
      "Bagging (NB)\n",
      "Train Accuracy : 0.691333333333\n",
      "Test Accuracy : 0.724\n"
     ]
    }
   ],
   "source": [
    "utility = Util()\n",
    "train_accuracy, test_accuracy = utility.CalculateAccuracy(BaggingClassifier(),\\\n",
    "            5, feats_train, opinions_train, feats_test, opinions_test)\n",
    "print 'Bagging (Trees)'\n",
    "print 'Train Accuracy : {}'.format(train_accuracy)\n",
    "print 'Test Accuracy : {}'.format(test_accuracy)\n",
    "\n",
    "train_accuracy, test_accuracy = utility.CalculateAccuracy(BaggingClassifier(base_estimator=LogisticRegression()),\\\n",
    "            5, feats_train, opinions_train, feats_test, opinions_test)\n",
    "print 'Bagging (Logit)'\n",
    "print 'Train Accuracy : {}'.format(train_accuracy)\n",
    "print 'Test Accuracy : {}'.format(test_accuracy)\n",
    "\n",
    "train_accuracy, test_accuracy = utility.CalculateAccuracy(BaggingClassifier(base_estimator=SVC()),\\\n",
    "            5, feats_train, opinions_train, feats_test, opinions_test)\n",
    "print 'Bagging (SVC)'\n",
    "print 'Train Accuracy : {}'.format(train_accuracy)\n",
    "print 'Test Accuracy : {}'.format(test_accuracy)\n",
    "\n",
    "train_accuracy, test_accuracy = utility.CalculateAccuracy(BaggingClassifier(base_estimator=BernoulliNB()),\\\n",
    "            5, feats_train, opinions_train, feats_test, opinions_test)\n",
    "print 'Bagging (NB)'\n",
    "print 'Train Accuracy : {}'.format(train_accuracy)\n",
    "print 'Test Accuracy : {}'.format(test_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AdaBoost (Trees)\n",
      "Train Accuracy : 0.7\n",
      "Test Accuracy : 0.724\n",
      "AdaBoost (SVC)\n",
      "Train Accuracy : 0.474666666667\n",
      "Test Accuracy : 0.4984\n",
      "AdaBoost (NB)\n",
      "Train Accuracy : 0.691333333333\n",
      "Test Accuracy : 0.724\n"
     ]
    }
   ],
   "source": [
    "train_accuracy, test_accuracy = utility.CalculateAccuracy(AdaBoostClassifier(),\\\n",
    "            5, feats_train, opinions_train, feats_test, opinions_test)\n",
    "print 'AdaBoost (Trees)'\n",
    "print 'Train Accuracy : {}'.format(train_accuracy)\n",
    "print 'Test Accuracy : {}'.format(test_accuracy)\n",
    "\n",
    "train_accuracy, test_accuracy = utility.CalculateAccuracy(AdaBoostClassifier(base_estimator=SVC(),algorithm='SAMME'),\\\n",
    "            5, feats_train, opinions_train, feats_test, opinions_test)\n",
    "print 'AdaBoost (SVC)'\n",
    "print 'Train Accuracy : {}'.format(train_accuracy)\n",
    "print 'Test Accuracy : {}'.format(test_accuracy)\n",
    "\n",
    "train_accuracy, test_accuracy = utility.CalculateAccuracy(AdaBoostClassifier(base_estimator=BernoulliNB()),\\\n",
    "            5, feats_train, opinions_train, feats_test, opinions_test)\n",
    "print 'AdaBoost (NB)'\n",
    "print 'Train Accuracy : {}'.format(train_accuracy)\n",
    "print 'Test Accuracy : {}'.format(test_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.73\n"
     ]
    }
   ],
   "source": [
    "word_list1 = []\n",
    "\n",
    "feats_train, feats_test, opinions_train, opinions_test = train_test_split(\\\n",
    "                    review_list, opinion_array)\n",
    "\n",
    "for i,review in enumerate(feats_train):\n",
    "    review_words = wordpunct_tokenize(review)\n",
    "    word_list.append((Counter(review_words),opinions_train[i]))\n",
    "\n",
    "classifier = nltk.NaiveBayesClassifier.train(word_list)\n",
    "\n",
    "for j,review in enumerate(feats_test):\n",
    "    review_words1 = wordpunct_tokenize(review)\n",
    "    word_list1.append((Counter(review_words1),opinions_test[j]))\n",
    "\n",
    "print nltk.classify.accuracy(classifier, word_list1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
