{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1200, 100)\n",
      "(1200, 100)\n",
      "(1200, 100)\n",
      "(1200, 100)\n",
      "(1200, 100)\n",
      "Sentiment #0\n",
      "film characters films character really just scenes scene audience best plot good time way performance actually great like make people\n",
      "\n",
      "Sentiment #1\n",
      "movie movies good plot seen did like really people funny bad just original characters know thing character little audience actually\n",
      "\n",
      "Sentiment #2\n",
      "life story love man family world new young like home does john doesn time old director year role best comedy\n",
      "\n",
      "Sentiment #3\n",
      "action like hes bad theres doesnt just dont films good guy big effects movies time plot special better make script\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Hyperparameters to tune\n",
    "#n_samples = 2000\n",
    "n_features = 100\n",
    "n_topics = 4\n",
    "n_top_words = 20\n",
    "\n",
    "moviesdf = pd.DataFrame(list(collection.find()))\n",
    "movies = moviesdf.as_matrix()\n",
    "moviestext = movies[:,1]\n",
    "     \n",
    "moviestext_train, moviestext_test = train_test_split(moviestext)\n",
    "kf = KFold(moviestext_train.shape[0], n_folds=5)\n",
    "vectorizer = TfidfVectorizer(max_features=n_features, stop_words='english')\n",
    "\n",
    "for train_index, test_index in kf:    \n",
    "    text_tfidf = vectorizer.fit_transform(list(\\\n",
    "            moviestext_train[train_index]))\n",
    "    print text_tfidf.shape\n",
    "    nmf = NMF(n_components=n_topics).fit(text_tfidf)\n",
    "#     print nmf.reconstruction_err_\n",
    "\n",
    "feature_names = vectorizer.get_feature_names()\n",
    "\n",
    "for idx, sentiment in enumerate(nmf.components_):\n",
    "    print \"Sentiment #{}\".format(idx)\n",
    "    print(\" \".join([feature_names[i]\n",
    "                    for i in sentiment.argsort()[:-n_top_words - 1:-1]]))\n",
    "    print"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "---------\n",
      "sklearn decomposition\n",
      "Reconstruction error: 0.006186\n",
      "Topic 0:\n",
      "film characters character films just really scenes scene audience performance good best great plot like\n",
      "Topic 1:\n",
      "movie movies seen good just plot funny characters like people did really know think bad\n",
      "Topic 2:\n",
      "action hes theres like bad doesnt dont just big effects good special films guy time\n",
      "Topic 3:\n",
      "life love story man new family world young does time doesn like john little role\n",
      "\n",
      "\n",
      "---------\n",
      "sklearn decomposition\n",
      "Reconstruction error: 0.006247\n",
      "Topic 0:\n",
      "film characters films character scenes plot really audience just scene story like performance good seen\n",
      "Topic 1:\n",
      "movie movies funny good like just bad seen characters plot think comedy know really original\n",
      "Topic 2:\n",
      "life love man story world new family john like time young does little doesn people\n",
      "Topic 3:\n",
      "action theres doesnt hes bad big dont just effects like special guy good films better\n",
      "\n",
      "\n",
      "---------\n",
      "sklearn decomposition\n",
      "Reconstruction error: 0.006207\n",
      "Topic 0:\n",
      "movie movies good funny know just characters seen plot like did people bad really think\n",
      "Topic 1:\n",
      "film films characters character really just scenes performance plot scene great audience fact good seen\n",
      "Topic 2:\n",
      "life story love man family new world young like doesn american time little does john\n",
      "Topic 3:\n",
      "action theres hes bad doesnt like big just dont guy good effects time special plot\n",
      "\n",
      "\n",
      "---------\n",
      "sklearn decomposition\n",
      "Reconstruction error: 0.006200\n",
      "Topic 0:\n",
      "film characters character films really just plot great audience best scenes good story performance scene\n",
      "Topic 1:\n",
      "movie movies know like seen did characters funny really just plot think good people thing\n",
      "Topic 2:\n",
      "action hes bad theres big doesnt like just effects dont good special films guy plot\n",
      "Topic 3:\n",
      "life story love man family new like world time young does little doesn old john\n",
      "\n",
      "\n",
      "---------\n",
      "sklearn decomposition\n",
      "Reconstruction error: 0.006191\n",
      "Topic 0:\n",
      "film character films characters just scenes really plot audience good scene seen time great best\n",
      "Topic 1:\n",
      "movie movies plot good like characters seen did funny just really know original bad think\n",
      "Topic 2:\n",
      "action bad hes theres doesnt just like dont big good guy comedy make really know\n",
      "Topic 3:\n",
      "life story love man world family new young like time john doesn people old does\n"
     ]
    }
   ],
   "source": [
    "n_topics = 4\n",
    "\n",
    "def reconst_mse(target, left, right):\n",
    "    return (np.array(target - left.dot(right))**2).mean()\n",
    "\n",
    "def describe_nmf_results(document_term_mat, W, H, n_top_words = 15):\n",
    "    print(\"Reconstruction error: %f\") %(reconst_mse(document_term_mat, W, H))\n",
    "    for topic_num, topic in enumerate(H):\n",
    "        print(\"Topic %d:\" % topic_num)\n",
    "        print(\" \".join([feature_words[i] \\\n",
    "                for i in topic.argsort()[:-n_top_words - 1:-1]]))\n",
    "    return\n",
    "\n",
    "moviesdf = pd.DataFrame(list(collection.find()))\n",
    "movies = moviesdf.as_matrix()\n",
    "moviestext = movies[:,1]\n",
    "     \n",
    "moviestext_train, moviestext_test = train_test_split(moviestext)\n",
    "kf = KFold(moviestext_train.shape[0], n_folds=5)\n",
    "vectorizer = TfidfVectorizer(max_features=n_features, stop_words='english')\n",
    "\n",
    "for train_index, test_index in kf:    \n",
    "    nmf = NMF(n_components=n_topics).fit(text_tfidf)\n",
    "    text_tfidf = vectorizer.fit_transform(list(moviestext_train[train_index]))\n",
    "    feature_words = vectorizer.get_feature_names()\n",
    "    \n",
    "    print(\"\\n\\n---------\\nsklearn decomposition\")\n",
    "    nmf = NMF(n_components=n_topics)\n",
    "    W_sklearn = nmf.fit_transform(text_tfidf)\n",
    "    H_sklearn = nmf.components_\n",
    "    describe_nmf_results(text_tfidf, W_sklearn, H_sklearn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from code.util import Util\n",
    "from pymongo import MongoClient\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer,CountVectorizer\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.decomposition import NMF\n",
    "from mlxtend.classifier import EnsembleClassifier\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'Figure' object has no attribute 'plot'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-93-445558bae289>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[0mscores\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtimes\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mutil\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTimevScore\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mclf1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mclf2\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0meclf\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mreview_sf\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mopinion_array\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m,\u001b[0m                       \u001b[1;34m'f1_weighted'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mfig\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 15\u001b[1;33m \u001b[0mfig\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtimes\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mscores\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'ro'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     16\u001b[0m \u001b[0mfig\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mxlabel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Seconds'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[0mfig\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mylabel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'F1 Weighted Score'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'Figure' object has no attribute 'plot'"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.figure.Figure at 0x20e04390>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#who doesn't love utility classes            \n",
    "util = Util()\n",
    "\n",
    "#some classifiers that have been tuned\n",
    "clf1 = LogisticRegression('l2')\n",
    "clf2 = BernoulliNB(alpha=0,fit_prior=True)\n",
    "#ensemble classifier\n",
    "eclf = EnsembleClassifier(clfs=[clf1, clf2], weights=[1,1])\n",
    "\n",
    "fig = plt.figure(1)\n",
    "\n",
    "#get lists of scores and times\n",
    "scores, times = util.TimevScore([clf1,clf2,eclf],review_sf,opinion_array,5,\\\n",
    "                       'f1_weighted',fig)\n",
    "\n",
    "fig.plot(times,scores,'ro')\n",
    "fig.xlabel('Seconds')\n",
    "fig.ylabel('F1 Weighted Score')\n",
    "for label, x, y in zip(['Logit','BernoulliNB','Ensemble'], times, scores):\n",
    "    plt.annotate(\n",
    "        label, \n",
    "        xy = (x, y), xytext = (40, 20),\n",
    "        textcoords = 'offset points', ha = 'right', va = 'bottom',\n",
    "        bbox = dict(boxstyle = 'round,pad=0.5', fc = 'yellow', alpha = 0.5),\n",
    "        arrowprops = dict(arrowstyle = '->', connectionstyle = 'arc3,rad=0'))\n",
    "fig.show()\n",
    "\n",
    "#get lists of scores and times\n",
    "scores, times = util.TimevScore([clf1,clf2,eclf],review_sf,opinion_array,5,\\\n",
    "                       'accuracy')\n",
    "\n",
    "# plt.plot(times,scores,'ro')\n",
    "# plt.xlabel('Seconds')\n",
    "# plt.ylabel('F1 Weighted Score')\n",
    "# for label, x, y in zip(['Logit','BernoulliNB','Ensemble'], times, scores):\n",
    "#     plt.annotate(\n",
    "#         label, \n",
    "#         xy = (x, y), xytext = (40, 20),\n",
    "#         textcoords = 'offset points', ha = 'right', va = 'bottom',\n",
    "#         bbox = dict(boxstyle = 'round,pad=0.5', fc = 'yellow', alpha = 0.5),\n",
    "#         arrowprops = dict(arrowstyle = '->', connectionstyle = 'arc3,rad=0'))\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.838   0.831   0.6985  0.832 ]\n",
      "[0.05299997329711914, 2.7219998836517334, 0.02200007438659668, 2.9790000915527344]\n"
     ]
    }
   ],
   "source": [
    "#data lists\n",
    "review_list, opinion_list, sentiword_list, sentiment_list, word_list,\\\n",
    "            pos, neg = [],[],[],[],[],[],[]\n",
    "#NMF hyper parameters\n",
    "n_topics = 1\n",
    "n_top_words = 1000\n",
    "\n",
    "#PyMongo variables\n",
    "client = MongoClient()\n",
    "db = client['reviews']\n",
    "collection = db['movies']\n",
    "reviews = collection.find()\n",
    "\n",
    "db1 = client['sentiment']\n",
    "collection1 = db1['bingliu']\n",
    "sentiments = collection1.find()\n",
    "\n",
    "#build review and label lists\n",
    "for review in reviews:\n",
    "    opinion_list.append(review['Opinion'])\n",
    "    review_list.append(review['Review'])\n",
    "\n",
    "opinion_array = np.array(opinion_list)    \n",
    "\n",
    "#build sentiment word, sentiment polarity, pos word, neg word\n",
    "for sentiment in sentiments:\n",
    "    sentiword_list.append(sentiment['Word'])\n",
    "    sentiment_list.append(sentiment['Sentiment'])\n",
    "    if sentiment['Sentiment'] == 1:\n",
    "        pos.append(sentiment['Word'])\n",
    "    elif sentiment['Sentiment'] == -1:\n",
    "        neg.append(sentiment['Word'])\n",
    "\n",
    "\n",
    "neg_vectorizer = TfidfVectorizer(decode_error='replace',strip_accents='unicode',\\\n",
    "                            vocabulary = neg, lowercase=True)\n",
    "neg_tfidf = neg_vectorizer.fit_transform(review_list[0:1000])\n",
    "pos_vectorizer = TfidfVectorizer(decode_error='replace',strip_accents='unicode',\\\n",
    "                            vocabulary = pos, lowercase=True)\n",
    "pos_tfidf = pos_vectorizer.fit_transform(review_list[1000:2000])\n",
    "\n",
    "neg_nmf = NMF(n_components=n_topics, random_state=1).fit(neg_tfidf)\n",
    "pos_nmf = NMF(n_components=n_topics, random_state=1).fit(pos_tfidf)\n",
    "\n",
    "neg_feature_names = neg_vectorizer.get_feature_names()\n",
    "pos_feature_names = pos_vectorizer.get_feature_names()\n",
    "\n",
    "for topic_idx, topic in enumerate(pos_nmf.components_):\n",
    "    pos_nmf = [pos_feature_names[i]\n",
    "                    for i in topic.argsort()[:-n_top_words - 1:-1]]\n",
    "\n",
    "for topic_idx, topic in enumerate(neg_nmf.components_):\n",
    "    neg_nmf = [neg_feature_names[i]\n",
    "                    for i in topic.argsort()[:-n_top_words - 1:-1]]\n",
    "    \n",
    "nmfvectorizer = TfidfVectorizer(decode_error='replace',strip_accents='unicode',\\\n",
    "                    vocabulary = pos_nmf+neg_nmf, lowercase=True)\n",
    "review_tfidf = nmfvectorizer.fit_transform(review_list)\n",
    "review_sf = review_tfidf.copy()\n",
    "\n",
    "#for every review\n",
    "for i, review_s in enumerate(review_tfidf):\n",
    "    #for every index (word) in the review\n",
    "    for idx in review_tfidf[i].indices:\n",
    "        if nmfvectorizer.vocabulary[idx] in neg_nmf:\n",
    "            review_sf[i, idx] = review_tfidf[i, idx]*-1\n",
    "        elif nmfvectorizer.vocabulary[idx] in pos_nmf:\n",
    "            review_sf[i, idx] = review_tfidf[i, idx]\n",
    "            \n",
    "util = Util()\n",
    "\n",
    "clf1 = LogisticRegression('l2')\n",
    "clf2 = RandomForestClassifier(max_features='log2',n_estimators=100,\\\n",
    "                              criterion='entropy')\n",
    "clf3 = BernoulliNB(alpha=0,fit_prior=True)\n",
    "eclf = EnsembleClassifier(clfs=[clf1, clf2, clf3], weights=[1,1,1])\n",
    "\n",
    "a, b = util.TimevScore([clf1,clf2,clf3,eclf],review_sf,opinion_array,5,\\\n",
    "                       'accuracy')\n",
    "print a\n",
    "print b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#NMF Hyperparameters\n",
    "n_topics = 2\n",
    "n_top_words = [10,20,50,100,1000]\n",
    "\n",
    "#Lists of data\n",
    "review_list, opinion_list, sentiword_list, sentiment_list,\\\n",
    "            pos, neg = [],[],[],[],[],[]\n",
    "    \n",
    "#PyMongo variables\n",
    "client = MongoClient()\n",
    "db = client['reviews']\n",
    "collection = db['movies']\n",
    "reviews = collection.find()\n",
    "\n",
    "#PyMongo variables for sentiment\n",
    "db1 = client['sentiment']\n",
    "collection1 = db1['bingliu']\n",
    "sentiments = collection1.find()\n",
    "\n",
    "#build review and label lists\n",
    "for review in reviews:\n",
    "    opinion_list.append(review['Opinion'])\n",
    "    review_list.append(review['Review'])\n",
    "\n",
    "#label array\n",
    "opinion_array = np.array(opinion_list)    \n",
    "\n",
    "#build sentiment word, sentiment polarity, pos word, neg word\n",
    "for sentiment in sentiments:\n",
    "    sentiword_list.append(sentiment['Word'])\n",
    "\n",
    "#vectorize words using sentiment words as vocab, lowercase, replace decode\n",
    "#errors and strip accents using unicode\n",
    "vectorizer = TfidfVectorizer(decode_error='replace',strip_accents='unicode',\\\n",
    "                            lowercase=True)\n",
    "review_tfidf = vectorizer.fit_transform(review_list)\n",
    "\n",
    "#NMF model fit using review_tfidf\n",
    "nmf = NMF(n_components=n_topics, random_state=1).fit(review_tfidf)\n",
    "#Feature names\n",
    "feature_names = vectorizer.get_feature_names()\n",
    "\n",
    "#loop through the topics in the nmf\n",
    "for topic_idx, topic in enumerate(nmf.components_):\n",
    "    #loop through the number of words in n_top_words\n",
    "    for n_top_word in n_top_words:\n",
    "        #build pos and neg word lists\n",
    "        if topic_idx == 0:\n",
    "            neg.append([feature_names[i]\n",
    "                        for i in topic.argsort()[:-n_top_word - 1:-1]])\n",
    "        elif topic_idx == 1:\n",
    "            pos.append([feature_names[i]\n",
    "                        for i in topic.argsort()[:-n_top_word - 1:-1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#loop through the number of words in n_top_words\n",
    "for j in xrange(len(n_top_words)):  \n",
    "    #build a vectorizer using the NMF sets of words\n",
    "    nmf_vectorizer = TfidfVectorizer(decode_error='replace',strip_accents='unicode',\\\n",
    "                                vocabulary = list(set(pos[j]+neg[j])), lowercase=True)\n",
    "    nmf_review_tfidf = nmf_vectorizer.fit_transform(review_list)        \n",
    "    #create a copy of the nmf_review_tfidf matrix to apply sentiment weights\n",
    "    nmf_review_sf = nmf_review_tfidf.copy()\n",
    "\n",
    "    #for every review\n",
    "    for i, review_s in enumerate(nmf_review_tfidf):\n",
    "        #for every index (word) in the review\n",
    "        for idx in nmf_review_tfidf[i].indices:\n",
    "            #apply sentiment weighting. if the word is in both lists then\n",
    "            #the weight value is reduced to 0\n",
    "            if nmf_vectorizer.vocabulary[idx] in neg and nmf_vectorizer.vocabulary[idx] in pos:\n",
    "                nmf_review_sf[i, idx] = 0\n",
    "            elif nmf_vectorizer.vocabulary[idx] in neg:\n",
    "                nmf_review_sf[i, idx] = nmf_review_tfidf[i, idx]*-1\n",
    "            elif nmf_vectorizer.vocabulary[idx] in pos:\n",
    "                nmf_review_sf[i, idx] = nmf_review_tfidf[i, idx]\n",
    "                \n",
    "    util = Util()\n",
    "    clf1 = LogisticRegression('l2')\n",
    "    a, b = util.TimevScore([clf1],nmf_review_sf,opinion_array,5,\\\n",
    "                       'accuracy')\n",
    "    print a\n",
    "    print b\n",
    "    print"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
